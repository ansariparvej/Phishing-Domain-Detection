{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install whois tldextract tld dnspython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF02RVZBD6_z",
        "outputId": "44ea9112-c8a2-4598-e4bb-1af24484987c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting whois\n",
            "  Downloading whois-0.9.27.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tldextract\n",
            "  Downloading tldextract-3.4.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tld\n",
            "  Downloading tld-0.13-py2.py3-none-any.whl (263 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.8/263.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython\n",
            "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from tldextract) (3.4)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from tldextract) (2.27.1)\n",
            "Collecting requests-file>=1.4 (from tldextract)\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract) (3.12.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (2.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from requests-file>=1.4->tldextract) (1.16.0)\n",
            "Building wheels for collected packages: whois\n",
            "  Building wheel for whois (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whois: filename=whois-0.9.27-py3-none-any.whl size=30469 sha256=479f3f17a1b116b445144197147a330f1d9ffb6e3ae89caece9f70ee6b60e6b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/17/36/d62eb5bcc416650499a7259d584c11e4a778de5ce0e72a8dbf\n",
            "Successfully built whois\n",
            "Installing collected packages: whois, tld, dnspython, requests-file, tldextract\n",
            "Successfully installed dnspython-2.3.0 requests-file-1.5.1 tld-0.13 tldextract-3.4.1 whois-0.9.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWH7m_6QkXPZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import whois\n",
        "import dns.resolver\n",
        "import requests\n",
        "import time\n",
        "import socket\n",
        "import ssl\n",
        "import re\n",
        "import urllib\n",
        "import urllib.request\n",
        "import urllib.parse\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "import tldextract\n",
        "from tld import get_tld\n",
        "import os    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.example.com/articles/technology/article.php?id=12345&page=1'\n",
        "\n",
        "url1 = 'https://www.google.com/'\n",
        "\n",
        "url2 = 'https://www.youtube.com/watch?v=ig73-IqQDJA&ab_channel=HUMTV'\n",
        "\n",
        "url3 = 'https://www.linkedin.com/jobs/?originalSubdomain=in'\n",
        "\n",
        "purl = 'http://www.paypal.com.security-verification.confirmation.account.validation.infos.us/'\n",
        "\n",
        "purl1 = 'http://www.carlodapa.com/AT&T/'\n",
        "\n",
        "purl2 = 'http://www.findmysupport-mex.us/PiRV8/'\n",
        "\n",
        "purl3 = 'http://www.selfindulgentpodcast.com/.well-known/14818/Login.html'\n"
      ],
      "metadata": {
        "id": "5YSgVPogkZ6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature 18: qty_tld_url\n",
        "domain = tldextract.extract(url).domain\n",
        "suffix = tldextract.extract(url).suffix\n",
        "\n",
        "if suffix:\n",
        "    print(len(domain + suffix) - len(suffix))\n",
        "    \n",
        "elif not suffix:\n",
        "    print(len(domain))\n",
        "    \n",
        "else:\n",
        "    print(0)"
      ],
      "metadata": {
        "id": "ITgyXvHpktkH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "033ce189-d904-47a3-eca5-f5950cda1a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# url_domain:\n",
        "parsed_url = urlparse(url1)\n",
        "domain = parsed_url.netloc\n",
        "print(domain)\n",
        "len(domain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGhJroCTGvB6",
        "outputId": "281825c9-b073-4e4d-803a-e62e8ff3bcff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "www.google.com\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# url_directory:\n",
        "\n",
        "features = []\n",
        "parsed_url = urlparse(purl)\n",
        "directory = parsed_url.path.rsplit('/', 1)[0]\n",
        "if not directory or directory == \"/\":\n",
        "    directory = -1\n",
        "    qty = 0\n",
        "    for qty in range(18):\n",
        "      features.append(-1)\n",
        "else:\n",
        "  features.append(len(directory))\n",
        "\n",
        "print(directory)\n",
        "print(features)\n",
        "print(len(features))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRl_bWmoHzDz",
        "outputId": "fa0d8edd-244d-42d8-9197-de960367c4db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1\n",
            "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
            "18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# url_file:\n",
        "\n",
        "features = []\n",
        "\n",
        "filename = os.path.basename(urlparse(purl3).path)\n",
        "if not filename or filename == \"/\":\n",
        "    filename = -1\n",
        "    qty = 0\n",
        "    for qty in range(18):\n",
        "      features.append(-1)\n",
        "else:\n",
        "  features.append(len(filename))\n",
        "\n",
        "print(filename)\n",
        "print(features)\n",
        "print(len(features))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtkTqD0tJOCz",
        "outputId": "d2b9d5b6-8447-4238-fb11-a75a1c1ade91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "login.php\n",
            "[9]\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import urlparse, parse_qs\n",
        "\n",
        "def extract_params(url):\n",
        "    params = urlparse(url).query\n",
        "    print(params)\n",
        "    if not params or params == None:\n",
        "        return -1\n",
        "    else:\n",
        "        num_params = len(params)\n",
        "        num_dots = params.count('.')\n",
        "        num_underscores = params.count('_')\n",
        "        num_equals = params.count('=')\n",
        "        num_ands = params.count('&')\n",
        "        num_tildes = params.count('~')\n",
        "        num_pluses = params.count('+')\n",
        "        num_dollars = params.count('$')\n",
        "        return [num_params, num_dots, num_underscores, num_equals, num_ands, num_tildes, num_pluses, num_dollars]\n"
      ],
      "metadata": {
        "id": "qPSm_ZWmrHh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_params(url2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgG3wOCyrL5F",
        "outputId": "1650a57a-0785-4941-aefa-b43aa401ac65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v=ig73-IqQDJA&ab_channel=HUMTV\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[30, 0, 1, 2, 1, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# resolving IP and external services:\n",
        "\n",
        "import whois\n",
        "import dns.resolver\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "import ssl\n",
        "import socket\n",
        "import urllib.parse\n",
        "import json\n",
        "import datetime\n",
        "import tldextract\n",
        "\n",
        "\n",
        "def extract_features(url):\n",
        "\n",
        "    features = []\n",
        "\n",
        "    # Extract domain name\n",
        "    parsed_url = urllib.parse.urlparse(url)\n",
        "    domain = parsed_url.netloc\n",
        "\n",
        "    # Feature 98: Time to response\n",
        "    try:\n",
        "        start = time.time()\n",
        "        response = requests.get(url, timeout=5)\n",
        "        end = time.time()\n",
        "        features.append(end - start)\n",
        "    except:\n",
        "        features.append(0.207 if not None else 0.207)\n",
        "\n",
        "    # SPF record check   \n",
        "    try:\n",
        "        spf = dns.resolver.resolve(domain, 'TXT').response.answer[0][0].to_text()\n",
        "        if 'v=spf' in spf:\n",
        "            features.append(1)\n",
        "        else:\n",
        "            features.append(0)\n",
        "    except:\n",
        "        features.append(-1)\n",
        "\n",
        "        \n",
        "    # ASN lookup\n",
        "    try:\n",
        "        ip = socket.gethostbyname(urlparse(url).netloc)\n",
        "        asn = requests.get(f\"https://ipapi.co/{ip}/asn/\").text.strip()\n",
        "        features.append(asn.strip('AS')) if asn else asn.strip('AS')\n",
        "    except:\n",
        "        features.append(0)\n",
        "\n",
        "\n",
        "    # Domain activation time (in days) \n",
        "    try:\n",
        "        domain = whois.whois(url)\n",
        "        creation_date = domain.creation_date\n",
        "        if isinstance(creation_date, list):\n",
        "            creation_date = creation_date[0]\n",
        "        features.append((datetime.datetime.now() - creation_date).days)\n",
        "            \n",
        "    except:\n",
        "        features.append(-1)\n",
        "      \n",
        "\n",
        "    # Domain expiration time (in days)\n",
        "    try:\n",
        "        expiration_date = whois.whois(domain).expiration_date\n",
        "        today = datetime.datetime.now()\n",
        "        features.append((expiration_date - today).days)           \n",
        "    except:\n",
        "        features.append(-1)\n",
        "    \n",
        "\n",
        "    # Number of resolved IPs\n",
        "    try:\n",
        "        ip_list = socket.getaddrinfo(domain, None)\n",
        "        features.append(len(ip_list))\n",
        "    except:\n",
        "        features.append(-1)\n",
        "\n",
        "    # Number of resolved NS\n",
        "    try:\n",
        "        domain = tldextract.extract(url).registered_domain\n",
        "        ns_list = dns.resolver.resolve(domain, 'NS')\n",
        "        features.append(len(ns_list))\n",
        "    except:\n",
        "        features.append(0)\n",
        "\n",
        "    # Number of MX servers\n",
        "    try:\n",
        "        domain = tldextract.extract(url).registered_domain\n",
        "        mx_list = dns.resolver.resolve(domain, 'MX')\n",
        "        features.append(len(mx_list))\n",
        "    except:\n",
        "        features.append(0)\n",
        "\n",
        "    # Time-To-Live (TTL)\n",
        "    try:\n",
        "        domain = tldextract.extract(url).registered_domain\n",
        "        ttl = dns.resolver.resolve(domain, 'NS').rrset.ttl\n",
        "        features.append(ttl)\n",
        "    except:\n",
        "        features.append(0)\n",
        "\n",
        "    # Has valid TLS/SSL certificate\n",
        "\n",
        "    try:\n",
        "        with socket.create_connection((urlparse(url).netloc, 443)) as sock:\n",
        "            with ssl.create_default_context().wrap_socket(sock, server_hostname=urlparse(url).netloc) as ssock:\n",
        "                cert = ssock.getpeercert()\n",
        "                if cert:\n",
        "                    features.append(1)\n",
        "                else:\n",
        "                    features.append(0)\n",
        "    except (ssl.SSLError, socket.gaierror, ConnectionRefusedError, TimeoutError):\n",
        "        features.append(0)\n",
        "    except Exception:\n",
        "        features.append(0)\n",
        "\n",
        "\n",
        "\n",
        "    # Number of redirects\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if not response:\n",
        "          features.append(-1)\n",
        "        else:\n",
        "          features.append(len(response.history))\n",
        "    except:\n",
        "        features.append(-1)\n",
        "\n",
        "   # Is URL shortened\n",
        "\n",
        "    response = requests.get(url, allow_redirects=False)\n",
        "\n",
        "    if 'location' in response.headers:\n",
        "        location = response.headers['location']\n",
        "        if url.split('/')[2] != location.split('/')[2]:\n",
        "            features.append(1)\n",
        "        else:\n",
        "            features.append(0)\n",
        "    else:\n",
        "        features.append(0)\n",
        "        \n",
        "\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "fP_o_pIUw-Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_features(purl3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUCM2Oh9D8X0",
        "outputId": "d4f14c79-a874-47d5-f90f-55ccc079822f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.24915719032287598, 0, '46606', -1, -1, 3, 2, 5, 21600, 1, -1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SPF record check   \n",
        "try:\n",
        "    spf = dns.resolver.resolve(domain, 'TXT').response.answer[0][0].to_text()\n",
        "    if 'v=spf' in spf:\n",
        "        print(1)\n",
        "    else:\n",
        "        print(0)\n",
        "except:\n",
        "    print(-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-y0zj0q1oCS",
        "outputId": "fc04be59-90bf-4f33-f2ab-25a20a2f3aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#asn\n",
        "\n",
        "ip = socket.gethostbyname(urlparse(url1).netloc)\n",
        "asn = requests.get(f\"https://ipapi.co/{ip}/asn/\").text.strip()\n",
        "if asn:\n",
        "  print((asn.strip('AS')) if asn else asn.strip('AS'))\n",
        "else:\n",
        "  print(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG_OlQfw5XqQ",
        "outputId": "f1b9d57d-85ba-4ea1-857f-7f8215896e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.linkedin.com/jobs/?originalSubdomain=in'\n",
        "import tldextract\n",
        "domain = tldextract.extract(url).registered_domain\n",
        "print(domain)\n",
        "#domain = whois.whois(domain)\n",
        "ns_list = dns.resolver.resolve(domain, 'NS')\n",
        "print('ns_list:', len(ns_list))\n",
        "\n",
        "domain = tldextract.extract(url).registered_domain\n",
        "mx_list = dns.resolver.resolve(domain, 'MX')\n",
        "print('mx_list:', len(mx_list))\n",
        "\n",
        "\n",
        "domain = tldextract.extract(url).registered_domain\n",
        "ttl = dns.resolver.resolve(domain, 'NS').rrset.ttl\n",
        "print('ttl:', ttl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM-y7E_6XK2s",
        "outputId": "330a1fbd-9671-43cc-ea15-d02513bfbc96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linkedin.com\n",
            "ns_list: 8\n",
            "mx_list: 4\n",
            "ttl: 21583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whois\n",
        "import os\n",
        "import dns.resolver\n",
        "import requests\n",
        "import time\n",
        "import socket\n",
        "import ssl\n",
        "import re\n",
        "import urllib\n",
        "import urllib.request\n",
        "import urllib.parse\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "import tldextract\n",
        "from tld import get_tld\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "import datetime\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define a function to extract features from the URL\n",
        "\n",
        "\n",
        "def extract_features(url):\n",
        "\n",
        "    features = []\n",
        "    \n",
        "    # Dataset attributes based on URL.\n",
        "    \n",
        "    # Feature 1: qty_dot_url\n",
        "    try:\n",
        "        features.append(url.count('.') if '.' in url else 0)\n",
        "    except:\n",
        "        features.append(0)\n",
        "\n",
        "    # Feature 2: qty_hyphen_url\n",
        "    try:\n",
        "        features.append(url.count('-') if '-' in url else 0)\n",
        "    except:\n",
        "        features.append(0)\n",
        "\n",
        "\n",
        "    # Feature 2: qty_underline_url\n",
        "    try:\n",
        "        features.append(url.count('_') if '_' in url else 0)\n",
        "    except:\n",
        "        features.append(0)\n",
        "\n",
        "\n",
        "    # Feature 4: qty_slash_url\n",
        "    try:\n",
        "        features.append(url.count('/') if '/' in url else 0)\n",
        "        \n",
        "    except:\n",
        "        features.append(0)\n",
        "\n",
        "\n",
        "    # Feature 18: qty_tld_url\n",
        "    domain = tldextract.extract(url).domain\n",
        "    suffix = tldextract.extract(url).suffix\n",
        "    \n",
        "    if suffix:\n",
        "        features.append(len(domain + suffix) - len(suffix))\n",
        "        \n",
        "    elif not suffix:\n",
        "        features.append(len(domain))\n",
        "        \n",
        "    else:\n",
        "        features.append(0)\n",
        "    \n",
        "    # Feature 19: length_url\n",
        "    try:\n",
        "        features.append(len(url))\n",
        "        \n",
        "    except:\n",
        "        features.append(0)\n",
        "\n",
        "    # Dataset attributes based on domain URL\n",
        "    parsed_url = urlparse(url)\n",
        "    domain = parsed_url.netloc\n",
        "    \n",
        "    # Feature 20: qty_dot_domain\n",
        "    try:\n",
        "        features.append(domain.count('.') if '.' in domain else 0)\n",
        "        \n",
        "    except:\n",
        "        features.append(0)\n",
        "    \n",
        "    \n",
        "    # Feature 21: qty_hyphen_domain\n",
        "    try:\n",
        "        features.append(domain.count('-') if '-' in domain else 0)\n",
        "        \n",
        "    except:\n",
        "        features.append(0)\n",
        "          \n",
        "    \n",
        "    # Feature 37: qty_vowels_domain\n",
        "    try:\n",
        "        vowels = set(['a', 'e', 'i', 'o', 'u', 'A','E','I','O','U'])\n",
        "        qty_vowels = sum(1 for c in domain if c in vowels)\n",
        "        features.append(qty_vowels)\n",
        "        \n",
        "    except:\n",
        "        features.append(0)\n",
        "    \n",
        "    \n",
        "    # Feature 38: domain_length\n",
        "    try:\n",
        "        features.append(len(domain) if domain else 0)\n",
        "        \n",
        "    except:\n",
        "        features.append(0)\n",
        "  \n",
        "        \n",
        "## Dataset attributes based on URL directory.\n",
        "    \n",
        "    parsed_url = urlparse(url)\n",
        "    # url_Path = Directory\n",
        "    url_path = parsed_url.path.rsplit('/', 1)[0]\n",
        "\n",
        "    if not url_path or url_path == '/':\n",
        "      url_path = -1\n",
        "      qty = 0\n",
        "      for qty in range(18):\n",
        "        features.append(-1)\n",
        "\n",
        "    else: \n",
        "      # Feature 41: qty_dot_directory\n",
        "      features.append(url_path.count('.') if '.' in url_path else 0)\n",
        "           \n",
        "      # Feature 42: qty_hyphen_directory\n",
        "      features.append(url_path.count('-') if '-' in url_path else 0)\n",
        "          \n",
        "      # Feature 43: qty_underline_directory\n",
        "      features.append(url_path.count('_') if '_' in url_path else 0)\n",
        "               \n",
        "      # Feature 44: qty_slash_directory\n",
        "      features.append(url_path.count('/') if '/' in url_path else 0)\n",
        "\n",
        "      # Feature 45: qty_questionmark_directory\n",
        "      features.append(url_path.count('?') if '?' in url_path else 0)\n",
        "\n",
        "      # Feature 46: qty_equal_directory\n",
        "      features.append(url_path.count('=') if '=' in url_path else 0) \n",
        "\n",
        "      # Feature 47: qty_at_directory\n",
        "      features.append(url_path.count('@') if '@' in url_path else 0)   \n",
        "\n",
        "      # Feature 48: qty_and_directory\n",
        "      features.append(url_path.count('&') if '&' in url_path else 0)  \n",
        "\n",
        "      # Feature 49: qty_exclamation_directory\n",
        "      features.append(url_path.count('!') if '!' in url_path else 0)\n",
        "\n",
        "      # Feature 50: qty_space_directory\n",
        "      features.append(url_path.count(' ') if ' ' in url_path else 0)    \n",
        "\n",
        "      # Feature 51: qty_tilde_directory\n",
        "      features.append(url_path.count('~') if '~' in url_path else 0)   \n",
        "\n",
        "      # Feature 52: qty_comma_directory \n",
        "      features.append(url_path.count(',') if ',' in url_path else 0) \n",
        "\n",
        "      # Feature 53: qty_plus_directory\n",
        "      features.append(url_path.count('+') if '+' in url_path else 0)   \n",
        "\n",
        "      # Feature 54: qty_asterisk_directory\n",
        "      features.append(url_path.count('*') if '*' in url_path else 0)   \n",
        "\n",
        "      # Feature 55: qty_hashtag_directory\n",
        "      features.append(url_path.count('#') if '#' in url_path else 0)\n",
        "\n",
        "      # Feature 56: qty_dollar_directory\n",
        "      features.append(url_path.count('$') if '$' in url_path else 0)  \n",
        "\n",
        "      # Feature 57: qty_percent_directory\n",
        "      features.append(url_path.count('%') if '%' in url_path else 0)\n",
        "\n",
        "      # Feature 58: directory_length \n",
        "      features.append(len(url_path) if url_path else 0)\n",
        "             \n",
        "## Dataset attributes based on URL ﬁle name.\n",
        "\n",
        "    file_name = os.path.basename(urlparse(url).path)\n",
        "\n",
        "    if not file_name or file_name == '/':\n",
        "      file_name = -1\n",
        "      qty = 0\n",
        "      for qty in range(18):\n",
        "        features.append(-1)\n",
        "\n",
        "    else: \n",
        "      # Feature 59: qty_dot_file\n",
        "      features.append(file_name.count('.') if '.' in file_name else 0)\n",
        "           \n",
        "      # Feature 60: qty_hyphen_file\n",
        "      features.append(file_name.count('-') if '-' in file_name else 0)\n",
        "          \n",
        "      # Feature 61: qty_underline_file\n",
        "      features.append(file_name.count('_') if '_' in file_name else 0)\n",
        "               \n",
        "      # Feature 62: qty_slash_file\n",
        "      features.append(file_name.count('/') if '/' in file_name else 0)\n",
        "\n",
        "      # Feature 63: qty_questionmark_file\n",
        "      features.append(file_name.count('?') if '?' in file_name else 0)\n",
        "\n",
        "      # Feature 64: qty_equal_file\n",
        "      features.append(file_name.count('=') if '=' in file_name else 0) \n",
        "\n",
        "      # Feature 65: qty_at_file\n",
        "      features.append(file_name.count('@') if '@' in file_name else 0)   \n",
        "\n",
        "      # Feature 66: qty_and_file\n",
        "      features.append(file_name.count('&') if '&' in file_name else 0)  \n",
        "\n",
        "      # Feature 67: qty_exclamation_file\n",
        "      features.append(file_name.count('!') if '!' in file_name else 0)\n",
        "\n",
        "      # Feature 68: qty_space_file\n",
        "      features.append(file_name.count(' ') if ' ' in file_name else 0)    \n",
        "\n",
        "      # Feature 69: qty_tilde_file\n",
        "      features.append(file_name.count('~') if '~' in file_name else 0)   \n",
        "\n",
        "      # Feature 70: qty_comma_file \n",
        "      features.append(file_name.count(',') if ',' in file_name else 0) \n",
        "\n",
        "      # Feature 71: qty_plus_file\n",
        "      features.append(file_name.count('+') if '+' in file_name else 0)   \n",
        "\n",
        "      # Feature 72: qty_asterisk_file\n",
        "      features.append(file_name.count('*') if '*' in file_name else 0)   \n",
        "\n",
        "      # Feature 73: qty_hashtag_file\n",
        "      features.append(file_name.count('#') if '#' in file_name else 0)\n",
        "\n",
        "      # Feature 74: qty_dollar_file\n",
        "      features.append(file_name.count('$') if '$' in file_name else 0)  \n",
        "\n",
        "      # Feature 75: qty_percent_file\n",
        "      features.append(file_name.count('%') if '%' in file_name else 0)\n",
        "\n",
        "      # Feature 76: file_length \n",
        "      features.append(len(file_name) if file_name else 0)\n",
        "       \n",
        "    \n",
        "## Dataset attributes based on URL parameters.\n",
        "\n",
        "    params = urlparse(url).query\n",
        "\n",
        "    if not params or params == None:\n",
        "        params = -1\n",
        "        qty = 0\n",
        "        for qty in range(8):\n",
        "          features.append(-1)\n",
        "    else:\n",
        "    \n",
        "      # Feature 77: qty_dot_params\n",
        "      features.append(params.count('.'))\n",
        "      \n",
        "      # Feature 79: qty_underline_params\n",
        "      features.append(params.count('_'))\n",
        "        \n",
        "      # Feature 82: qty_equal_params\n",
        "      features.append(params.count('='))\n",
        "          \n",
        "      # Feature 84: qty_and_params\n",
        "      features.append(params.count('&'))\n",
        "          \n",
        "      # Feature 87: qty_tilde_params\n",
        "      features.append(params.count('~'))\n",
        "          \n",
        "      # Feature 89: qty_plus_params\n",
        "      features.append(params.count('+'))\n",
        "      \n",
        "      # Feature 92: qty_dollar_params\n",
        "      features.append(params.count('$'))\n",
        "          \n",
        "      # Feature 94: params_length_characters\n",
        "      features.append(len(params))\n",
        "          \n",
        "              \n",
        "## Dataset attributes based on resolving URL and external services.\n",
        "\n",
        "    # Extract domain name\n",
        "    parsed_url = urllib.parse.urlparse(url)\n",
        "    domain = parsed_url.netloc\n",
        "\n",
        "    # Feature 98: Time to response\n",
        "    try:\n",
        "        start = time.time()\n",
        "        response = requests.get(url, timeout=5)\n",
        "        end = time.time()\n",
        "        features.append(end - start)\n",
        "    except:\n",
        "        features.append(0.207 if not None else 0.207)\n",
        "    \n",
        "    # Feature 99: Presence of SPF record\n",
        "    try:\n",
        "        spf = dns.resolver.resolve(domain, 'TXT').response.answer[0][0].to_text()\n",
        "        if 'v=spf' in spf:\n",
        "            features.append(1)\n",
        "        else:\n",
        "            features.append(0)\n",
        "    except:\n",
        "        features.append(-1)\n",
        "    \n",
        "    # Feature 100: Autonomous System Number (ASN) of IP address\n",
        "    try:\n",
        "        ip = socket.gethostbyname(urlparse(url).netloc)\n",
        "        asn = requests.get(f\"https://ipapi.co/{ip}/asn/\").text.strip()\n",
        "        features.append(asn.strip('AS')) if asn else asn.strip('AS')\n",
        "    except:\n",
        "        features.append(0)\n",
        "\n",
        "    # Feature 101: Time to domain activation\n",
        "    try:\n",
        "        domain = whois.whois(url)\n",
        "        creation_date = domain.creation_date\n",
        "        if isinstance(creation_date, list):\n",
        "            creation_date = creation_date[0]\n",
        "        features.append((datetime.datetime.now() - creation_date).days)\n",
        "            \n",
        "    except:\n",
        "        features.append(-1)\n",
        "    \n",
        "    # Feature 102: Time to domain expiration\n",
        "    try:\n",
        "        expiration_date = whois.whois(domain).expiration_date\n",
        "        today = datetime.datetime.now()\n",
        "        features.append((expiration_date - today).days)           \n",
        "    except:\n",
        "        features.append(-1)\n",
        "    \n",
        "    # Feature 103: Quantity of resolved IPs\n",
        "    try:\n",
        "        ip_list = socket.getaddrinfo(domain, None)\n",
        "        features.append(len(ip_list))\n",
        "    except:\n",
        "        features.append(-1)\n",
        "    \n",
        "    # Feature 104: Quantity of name servers\n",
        "    try:\n",
        "        domain = tldextract.extract(url).registered_domain\n",
        "        ns_list = dns.resolver.resolve(domain, 'NS')\n",
        "        features.append(len(ns_list))\n",
        "    except:\n",
        "        features.append(0)\n",
        "    \n",
        "    # Feature 105: Quantity of MX servers\n",
        "    try:\n",
        "        domain = tldextract.extract(url).registered_domain\n",
        "        mx_list = dns.resolver.resolve(domain, 'MX')\n",
        "        features.append(len(mx_list))\n",
        "    except:\n",
        "        features.append(0)\n",
        "    \n",
        "    # Feature 106: TTL value of hostname\n",
        "    try:\n",
        "        domain = tldextract.extract(url).registered_domain\n",
        "        ttl = dns.resolver.resolve(domain, 'NS').rrset.ttl\n",
        "        features.append(ttl)\n",
        "    except:\n",
        "        features.append(0)\n",
        "    \n",
        "    # Feature 107: Presence of TLS/SSL certificate\n",
        "    try:\n",
        "        with socket.create_connection((urlparse(url).netloc, 443)) as sock:\n",
        "            with ssl.create_default_context().wrap_socket(sock, server_hostname=urlparse(url).netloc) as ssock:\n",
        "                cert = ssock.getpeercert()\n",
        "                if cert:\n",
        "                    features.append(1)\n",
        "                else:\n",
        "                    features.append(0)\n",
        "    except (ssl.SSLError, socket.gaierror, ConnectionRefusedError, TimeoutError):\n",
        "        features.append(0)\n",
        "    except Exception:\n",
        "        features.append(0)\n",
        "    \n",
        "    # Feature 108: Number of redirects\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if not response:\n",
        "          features.append(-1)\n",
        "        else:\n",
        "          features.append(len(response.history))\n",
        "    except:\n",
        "        features.append(-1)\n",
        "\n",
        "\n",
        "    # Feature 111: URL shortened\n",
        "    response = requests.get(url, allow_redirects=False)\n",
        "\n",
        "    if 'location' in response.headers:\n",
        "        location = response.headers['location']\n",
        "        if url.split('/')[2] != location.split('/')[2]:\n",
        "            features.append(1)\n",
        "        else:\n",
        "            features.append(0)\n",
        "    else:\n",
        "        features.append(0)\n",
        "        \n",
        "    \n",
        "    return features\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "NFEhrQO7yzty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_features(url2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDratHrQy7N6",
        "outputId": "d7be0aa4-b768-4834-f6fc-e4479526600b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 7,\n",
              " 60,\n",
              " 2,\n",
              " 0,\n",
              " 5,\n",
              " 15,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 5,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 30,\n",
              " 0.5380253791809082,\n",
              " -1,\n",
              " '15169',\n",
              " -1,\n",
              " -1,\n",
              " 60,\n",
              " 4,\n",
              " 1,\n",
              " 21600,\n",
              " 1,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(extract_features(purl1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnSGQeLVz3KV",
        "outputId": "fe6c9889-4838-4d9b-cd9d-75ecfdc90b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}